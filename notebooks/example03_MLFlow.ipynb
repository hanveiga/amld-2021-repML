{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce49b899",
   "metadata": {},
   "source": [
    "# AMLD 2021 - Workshop\n",
    "\n",
    "> ##### Machine Learning in Science: Encoding physical constraints and good development practices\n",
    "\n",
    "\n",
    "## Example 03 - Tools: Model tracking with MLFlow\n",
    "\n",
    "In this notebook, we introduce MLFlow. MLFlow makes it easy to keep track of the models you have run, their hyperparameters, and their performances. \n",
    "\n",
    "### Workshop Organizers\n",
    "\n",
    "* Dr. Maria Han Veiga (University of Michigan, USA)\n",
    "\n",
    "* Dr. Miles Timpe (University of Zurich, Switzerland)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reserved-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(in_target, in_n1, in_n2=0, in_n3=0):\n",
    "    \"\"\"Trains a single model given a hyperparameter set.\"\"\"\n",
    "    \n",
    "    import os\n",
    "    import random\n",
    "    import warnings\n",
    "    import sys\n",
    "\n",
    "    from joblib import dump, load\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn import preprocessing\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    \n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    \n",
    "    import logging\n",
    "    logging.basicConfig(level=logging.WARN)\n",
    "    logger = logging.getLogger(__name__)\n",
    "    \n",
    "    # We can define a global seed value to make our lives easier\n",
    "    seed = 42\n",
    "\n",
    "    # Set random seeds\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    \n",
    "    def neural_network(n1, n2, n3):\n",
    "        \n",
    "        layer_sizes = [n1,n2,n3]\n",
    "        \n",
    "        if n3 == 0:\n",
    "            layer_sizes = [n1,n2]\n",
    "        if n2 == 0:\n",
    "            layer_sizes = [n1]\n",
    "\n",
    "        # Define model (MLP) with sklearn\n",
    "        return MLPRegressor(hidden_layer_sizes=layer_sizes,\n",
    "                            max_iter=1000, early_stopping=True,\n",
    "                            random_state=seed)\n",
    "\n",
    "\n",
    "    def load_data(target):\n",
    "        \"\"\"Load train and test datasets.\"\"\"\n",
    "\n",
    "        features = ['mtotal', 'gamma', 'b_inf', 'v_inf',\n",
    "                    'targ_core_fraction', 'targ_omega', 'targ_theta', 'targ_phi',\n",
    "                    'proj_core_fraction', 'proj_omega', 'proj_theta', 'proj_phi',\n",
    "                    'lr_mass', target]\n",
    "\n",
    "        try:\n",
    "            x_train = pd.read_csv('../datasets/train.csv', usecols=features)\n",
    "        except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download train.csv! Error: %s\", e)\n",
    "\n",
    "        try:\n",
    "            x_test  = pd.read_csv('../datasets/test.csv', usecols=features)\n",
    "        except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download test.csv! Error: %s\", e)\n",
    "\n",
    "\n",
    "        x_train = x_train[x_train['lr_mass'] > 0]\n",
    "        x_test = x_test[x_test['lr_mass'] > 0]\n",
    "\n",
    "        if target != 'lr_mass':\n",
    "            x_train.pop('lr_mass')\n",
    "            x_test.pop('lr_mass')\n",
    "\n",
    "        y_train = x_train.pop(target)\n",
    "        y_test  = x_test.pop(target)\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "    def scale_data(x_train, y_train, x_test, y_test):\n",
    "\n",
    "        # Scale features\n",
    "        x_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "        # Fit scaler to training data\n",
    "        x_scaler.fit(x_train)\n",
    "\n",
    "        # Save scaler\n",
    "        dump(x_scaler, f\"../models/mlflow/x_scaler.joblib\")\n",
    "\n",
    "        # Make sure to apply same scaler to train and test!\n",
    "        scaled_x_train = x_scaler.transform(x_train)\n",
    "        scaled_x_test  = x_scaler.transform(x_test)\n",
    "\n",
    "        scaled_x_train = pd.DataFrame(scaled_x_train, columns=x_train.columns)\n",
    "        scaled_x_test  = pd.DataFrame(scaled_x_test, columns=x_test.columns)\n",
    "\n",
    "        del x_scaler\n",
    "\n",
    "\n",
    "        # Scale target\n",
    "        y_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "        y_scaler.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "        # Save scaler\n",
    "        dump(y_scaler, f\"../models/mlflow/y_scaler_{target}.joblib\")\n",
    "\n",
    "        scaled_y_train = y_scaler.transform(y_train.values.reshape(-1, 1))\n",
    "        scaled_y_test  = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "        scaled_y_train = pd.Series(data=np.squeeze(scaled_y_train), name=target)\n",
    "        scaled_y_test  = pd.Series(data=np.squeeze(scaled_y_test), name=target)\n",
    "\n",
    "        del y_scaler\n",
    "\n",
    "\n",
    "        return scaled_x_train, scaled_y_train, scaled_x_test, scaled_y_test\n",
    "\n",
    "    \n",
    "    \n",
    "    # Check to make sure that the target is valid\n",
    "    if in_target not in ['lr_mass', 'slr_mass', 'debris_mass']:\n",
    "        logger.exception(\n",
    "            \"Target name is invalid! Error: %s\", e)\n",
    "    else:\n",
    "        target = in_target\n",
    "    \n",
    "    # Check to make sure the MLP has at least one neuron\n",
    "    if int(in_n1) <= 0:\n",
    "        logger.exception(\n",
    "            \"n1 must be greater than zero! Error: %s\", e)\n",
    "    else:\n",
    "        n1 = int(in_n1)\n",
    "\n",
    "    # Set default values if no n2 is provided\n",
    "    if int(in_n2) <= 0:\n",
    "        n2 = 0\n",
    "    else:\n",
    "        n2 = int(in_n2)\n",
    "\n",
    "    # Set default values if no n3 is provided\n",
    "    if int(in_n3) <= 0:\n",
    "        n3 = 0\n",
    "    else:\n",
    "        n3 = int(in_n3)\n",
    "        \n",
    "        \n",
    "    # Load and scale data\n",
    "    x_train, y_train, x_test, y_test = load_data(target)\n",
    "\n",
    "    scaled_x_train, scaled_y_train, scaled_x_test, scaled_y_test = scale_data(\n",
    "        x_train, y_train, x_test, y_test)\n",
    "        \n",
    "\n",
    "    # Useful for multiple runs (only doing one run in this sample notebook)    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        model = neural_network(n1, n2, n3)\n",
    "        \n",
    "        # Fit model\n",
    "        model.fit(scaled_x_train, scaled_y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        scaled_y_pred = model.predict(scaled_x_test)\n",
    "\n",
    "        # Apply inverse scaling to the model predictions\n",
    "        y_scaler = load(f\"../models/mlflow/y_scaler_{target}.joblib\")\n",
    "\n",
    "        y_pred = pd.Series(y_scaler.inverse_transform(scaled_y_pred), name='y_pred').values\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(y_test, y_pred)\n",
    "        \n",
    "        #dump(model, f\"../models/regressor_mlp_{target}.joblib\") \n",
    "\n",
    "        # Print out metrics\n",
    "        print(f\"Target: {target}\")\n",
    "        print(f\"MLP (n1={n1}, n2={n2}, n3={n3}):\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE:  {mae:4f}\")\n",
    "        print(f\"  R2:   {r2:.4f}\")\n",
    "\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"target\", target)\n",
    "        mlflow.log_param(\"n1\", n1)\n",
    "        mlflow.log_param(\"n2\", n2)\n",
    "        mlflow.log_param(\"n3\", n3)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c516e7a",
   "metadata": {},
   "source": [
    "### Train models and track them with MLFlow\n",
    "\n",
    "The train function will call the code above and train, test, and log a model for the given input parameters; in this case the number of neurons in the 1-3 hidden layers. Let's train a few different network configurations and then we'll use the MLFlow UI to see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "319c935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: lr_mass\n",
      "MLP (n1=24, n2=24, n3=24):\n",
      "  RMSE: 0.0547\n",
      "  MAE:  0.033646\n",
      "  R2:   0.9866\n"
     ]
    }
   ],
   "source": [
    "train('lr_mass', 24, 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56813001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: lr_mass\n",
      "MLP (n1=24, n2=24, n3=0):\n",
      "  RMSE: 0.0497\n",
      "  MAE:  0.029545\n",
      "  R2:   0.9889\n"
     ]
    }
   ],
   "source": [
    "train('lr_mass', 24, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea1f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: lr_mass\n",
      "MLP (n1=24, n2=0, n3=0):\n",
      "  RMSE: 0.0647\n",
      "  MAE:  0.041469\n",
      "  R2:   0.9813\n"
     ]
    }
   ],
   "source": [
    "train('lr_mass', 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "462ef53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: slr_mass\n",
      "MLP (n1=8, n2=4, n3=0):\n",
      "  RMSE: 0.0501\n",
      "  MAE:  0.028197\n",
      "  R2:   0.9420\n"
     ]
    }
   ],
   "source": [
    "train('slr_mass', 8, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a6d8603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: debris_mass\n",
      "MLP (n1=2, n2=2, n3=2):\n",
      "  RMSE: 0.2975\n",
      "  MAE:  0.212318\n",
      "  R2:   -0.0006\n"
     ]
    }
   ],
   "source": [
    "train('debris_mass', 2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300c76f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: lr_mass\n",
      "MLP (n1=3, n2=3, n3=3):\n",
      "  RMSE: 0.1224\n",
      "  MAE:  0.088305\n",
      "  R2:   0.9329\n"
     ]
    }
   ],
   "source": [
    "train('lr_mass', 3, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ef293",
   "metadata": {},
   "source": [
    "### View runs\n",
    "\n",
    "Once we have trained a few models, let's see how MLFLow can help us keep track of our previous runs. Make sure you're in the `amld-2021-repML/notebooks` directory, then type `mlflow ui` into the terminal and hit enter. Then paste http://localhost:5000/ in your browser to pull up the MLFLow user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429852e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
