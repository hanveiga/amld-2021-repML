{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "868f6c02",
   "metadata": {},
   "source": [
    "# AMLD 2021\n",
    "\n",
    "> ##### Machine Learning in Science: Encoding physical constraints and good development practices\n",
    "\n",
    "\n",
    "## Example 04 - Physics \"embedding\" through the neural network\n",
    "\n",
    "In this notebook, we demonstrating a method for ensuring physical consistency of the predictions by incoorporating knownledge in the neural network\n",
    "\n",
    "### Workshop Organizers\n",
    "\n",
    "* Dr. Maria Han Veiga (University of Michigan, USA)\n",
    "\n",
    "* Dr. Miles Timpe (University of Zurich, Switzerland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d93f91",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea572fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Subtract, Lambda, add, ReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Global seed value\n",
    "seed = 42\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "\n",
    "# Versions can also influence reproducibility\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7deff8",
   "metadata": {},
   "source": [
    "### Load test data and scalers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1680a116",
   "metadata": {},
   "source": [
    "We focus first on lr_mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f673b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'lr_mass'\n",
    "\n",
    "features = ['mtotal', 'gamma', 'b_inf', 'v_inf',\n",
    "            'targ_core_fraction', 'targ_omega', 'targ_theta', 'targ_phi',\n",
    "            'proj_core_fraction', 'proj_omega', 'proj_theta', 'proj_phi',\n",
    "            target]\n",
    "\n",
    "x_train = pd.read_csv('../datasets/train.csv', usecols=features)\n",
    "x_test  = pd.read_csv('../datasets/test.csv', usecols=features)\n",
    "\n",
    "y_train = x_train.pop(target)\n",
    "y_test  = x_test.pop(target)\n",
    "\n",
    "# Load scalers and scale targets\n",
    "scalers = {}\n",
    "data = {}\n",
    "\n",
    "y_scaler = load(f\"../models/y_scaler_{target}.joblib\")\n",
    "\n",
    "scaled_y_train = y_scaler.transform(y_train.values.reshape(-1, 1))\n",
    "scaled_y_test  = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "    \n",
    "# Scale features\n",
    "x_scaler = load(f\"../models/x_scaler.joblib\")\n",
    "\n",
    "scaled_x_train = pd.DataFrame(x_scaler.transform(x_train), columns=x_train.columns)\n",
    "scaled_x_test = pd.DataFrame(x_scaler.transform(x_test), columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a53e15e",
   "metadata": {},
   "source": [
    "### Setup physics informed neural network\n",
    "\n",
    "Here, we will first focus on the 'lr_mass' target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7f97d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously trained model\n",
    "model_uninformed = keras.models.load_model(f\"../models/regressor_mlp_{target}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47b923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, input_size = scaled_x_train.shape\n",
    "\n",
    "input1 = keras.layers.Input(shape=(16,))\n",
    "x1 = keras.layers.Dense(8, activation='relu')(input1)\n",
    "input2 = keras.layers.Input(shape=(32,))\n",
    "x2 = keras.layers.Dense(8, activation='relu')(input2)\n",
    "# Equivalent to subtracted = keras.layers.subtract([x1, x2])\n",
    "subtracted = keras.layers.Subtract()([x1, x2])\n",
    "out = keras.layers.Dense(4)(subtracted)\n",
    "\n",
    "model = keras.models.Model(inputs=[input1, input2], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99397cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ -1.]\n",
      "  [ 11.]\n",
      "  [ 23.]\n",
      "  [ 35.]\n",
      "  [ 47.]\n",
      "  [ 59.]\n",
      "  [ 71.]\n",
      "  [ 83.]\n",
      "  [ 95.]\n",
      "  [107.]]]\n",
      "[[-1.  0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]\n",
      "[[[  0   1   2   3   4   5   6   7   8   9  10  11]\n",
      "  [ 12  13  14  15  16  17  18  19  20  21  22  23]\n",
      "  [ 24  25  26  27  28  29  30  31  32  33  34  35]\n",
      "  [ 36  37  38  39  40  41  42  43  44  45  46  47]\n",
      "  [ 48  49  50  51  52  53  54  55  56  57  58  59]\n",
      "  [ 60  61  62  63  64  65  66  67  68  69  70  71]\n",
      "  [ 72  73  74  75  76  77  78  79  80  81  82  83]\n",
      "  [ 84  85  86  87  88  89  90  91  92  93  94  95]\n",
      "  [ 96  97  98  99 100 101 102 103 104 105 106 107]\n",
      "  [108 109 110 111 112 113 114 115 116 117 118 119]]]\n",
      "[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "r1 = Input(shape=(10,12))\n",
    "r2 = Input(shape=(10,12))\n",
    "\n",
    "# Lambda for subtracting two tensors\n",
    "#minus_r2 = Lambda(lambda x: -x)(r2)\n",
    "#subtracted = \n",
    "r3 =  tf.gather(r1,[0],axis=2)\n",
    "r4 =  tf.gather(r2,[0],axis=2)\n",
    "out= Lambda(lambda x: x)(Subtract()([r3,r4]))\n",
    "\n",
    "model = keras.Model([r1,r2],out)\n",
    "\n",
    "a = np.arange(120).reshape([1,10,12])\n",
    "b = np.ones(120).reshape([1,10,12])\n",
    "\n",
    "print(model.predict([a,b]))\n",
    "# [[[[ 1.  0.]\n",
    "#    [ 1.  4.]]]]\n",
    "\n",
    "print(a[:,0]-b[:,0])\n",
    "#print((a-b))\n",
    "# [[[[ 1.  0.]\n",
    "#    [ 1.  4.]]]]\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb3fbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction r2_score: 0.8964\n"
     ]
    }
   ],
   "source": [
    "# Define custom loss function\n",
    "def custom_loss_wrapper(input_tensor, overshoot_weight=0.0):\n",
    "    def custom_loss(y_true,y_pred):\n",
    "        s = tf.gather(input_tensor,[0],axis=1)\n",
    "        #s = tf.print(s, [s], \"shape\",output_stream=sys.stdout)\n",
    "        s = Lambda(lambda x: x)(s)\n",
    "        #overshoot = K.sum(ReLU()(Lambda(lambda x: -x)(Subtract()([s1,y_pred]))))\n",
    "        #print(K.sum(overshoot).eval())\n",
    "        #d = tf.print(overshoot, [overshoot], \"Inside loss function\",output_stream=sys.stdout)\n",
    "        return keras.losses.mean_squared_error(y_true, y_pred) #+ overshoot\n",
    "    return custom_loss\n",
    "\n",
    "batchsize=128\n",
    "inputs = Input(shape=(input_size,))\n",
    "f = Dense(24,activation='relu')(inputs)\n",
    "f = Dense(24,activation='relu')(f)\n",
    "f = Dense(24,activation='relu')(f)\n",
    "outputs = Dense(1)(f)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile('Adam', loss=custom_loss_wrapper(inputs), metrics=\"mse\")\n",
    "\n",
    "# Fit model\n",
    "model.fit(x_train, y_train, validation_split = 0.05, epochs=100, callbacks=[EarlyStopping(patience=70)],verbose=0)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Apply inverse scaling to the model predictions\n",
    "#y_scaler = load(f\"../models/y_scaler_{target}.joblib\")\n",
    "\n",
    "#y_pred = pd.Series(y_scaler.inverse_transform(scaled_y_pred.flatten()), name='y_pred').values\n",
    "\n",
    "# Calculate the quality of the predictions with the r2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Save the model with keras\n",
    "model.save(f\"../models/regressor_mlp_customloss_{target}.keras\")\n",
    "\n",
    "print(f\"Prediction r2_score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513c678",
   "metadata": {},
   "source": [
    "### Physical constraints: mass conservation\n",
    "\n",
    "From the r2 scores reported above, it's clear that the predictions of the SLR (second largest remnant) mass are significantly worse than the predictions for the other targets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a93f865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_two(row):    \n",
    "    # We use the most accurate two regressors and the third is replaced by the residual.\n",
    "    \n",
    "    # Ensure no negative masses\n",
    "    m_lr = np.max([0.0, row['lr_mass']])\n",
    "    m_slr = np.max([0.0, row['slr_mass']])\n",
    "    m_deb = np.max([0.0, row['debris_mass']])\n",
    "    \n",
    "    \n",
    "    if m_lr >= row['m_tot']:\n",
    "        \n",
    "        return row['m_tot'], 0.0, 0.0\n",
    "    \n",
    "    elif m_lr + m_deb > row['m_tot']:\n",
    "        \n",
    "        return m_lr, 0.0, row['m_tot'] - m_lr\n",
    "    \n",
    "    else:\n",
    "\n",
    "        m_slr = row['m_tot'] - m_lr - m_deb\n",
    "\n",
    "        return m_lr, m_slr, m_deb\n",
    "\n",
    "\n",
    "data[['lr_pred', 'slr_pred', 'debris_pred']] = data.apply(best_two, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748dc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_residual(row):\n",
    "    # Calculate the normalized mass residual\n",
    "    \n",
    "    dM = row['m_tot'] - row['lr_pred'] - row['slr_pred'] - row['debris_pred']\n",
    "    \n",
    "    return dM / row['m_tot']\n",
    "\n",
    "\n",
    "data['new_residual'] = data.apply(new_residual, axis=1)\n",
    "\n",
    "\n",
    "print(f\"deltaM min = {data.new_residual.min()}\")\n",
    "print(f\"deltaM max = {data.new_residual.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e8f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "\n",
    "ax.set_xlabel(r'$\\Delta M$ $(M_{tot})$')\n",
    "\n",
    "ax.hist(data.residual, bins=np.linspace(-0.35, 0.35, num=100),\n",
    "        color='dodgerblue')\n",
    "\n",
    "ax.axvline(x=0, color='red', alpha=1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10f4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Mass':>8}{'Unconstrained':>22}{'Constrained':>18}\")\n",
    "\n",
    "for name in targets:\n",
    "    \n",
    "    name = name.split('_')[0]\n",
    "    \n",
    "    # Load true values\n",
    "    y_test = data[f\"{name}_true\"]\n",
    "    y_pred = data[f\"{name}_mass\"]\n",
    "    y_phys = data[f\"{name}_pred\"]\n",
    "    \n",
    "    # Calculate the quality of the predictions with the r2 score\n",
    "    r2_pred = r2_score(y_test, y_pred)\n",
    "    r2_phys = r2_score(y_test, y_phys)\n",
    "    \n",
    "    \n",
    "    print(f\"{name:>8}{r2_pred:>15.4f}{r2_phys:>20.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6917845a",
   "metadata": {},
   "source": [
    "### Comments\n",
    "\n",
    "As we can see from the results above, we have traded a bit of accuracy in return for obeying physics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb84481",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(3, 2, figsize=(12,12), sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "\n",
    "# LR\n",
    "y_test_norm = []\n",
    "y_pred_norm = []\n",
    "y_phys_norm = []\n",
    "\n",
    "for m_tot, y_t, y_p, y_c in zip(x_test.mtotal, data.lr_true, data.lr_mass, data.lr_pred):\n",
    "    y_test_norm.append( y_t / m_tot )\n",
    "    y_pred_norm.append( y_p / m_tot )\n",
    "    y_phys_norm.append( y_c / m_tot )\n",
    "    \n",
    "    \n",
    "ax = ax1[0][0]\n",
    "\n",
    "ax.set_title('Unconstrained')\n",
    "ax.set_ylabel('Predicted Value (LR)')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_pred_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "ax = ax1[0][1]\n",
    "\n",
    "ax.set_title('Constrained')\n",
    "\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_phys_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "\n",
    "# SLR\n",
    "y_test_norm = []\n",
    "y_pred_norm = []\n",
    "y_phys_norm = []\n",
    "\n",
    "for m_tot, y_t, y_p, y_c in zip(x_test.mtotal, data.slr_true, data.slr_mass, data.slr_pred):\n",
    "    y_test_norm.append( y_t / m_tot )\n",
    "    y_pred_norm.append( y_p / m_tot )\n",
    "    y_phys_norm.append( y_c / m_tot )\n",
    "    \n",
    "    \n",
    "ax = ax1[1][0]\n",
    "\n",
    "ax.set_ylabel('Predicted Value (SLR)')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_pred_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "ax = ax1[1][1]\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_phys_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "\n",
    "# Debris\n",
    "y_test_norm = []\n",
    "y_pred_norm = []\n",
    "y_phys_norm = []\n",
    "\n",
    "for m_tot, y_t, y_p, y_c in zip(x_test.mtotal, data.debris_true, data.debris_mass, data.debris_pred):\n",
    "    y_test_norm.append( y_t / m_tot )\n",
    "    y_pred_norm.append( y_p / m_tot )\n",
    "    y_phys_norm.append( y_c / m_tot )\n",
    "    \n",
    "    \n",
    "ax = ax1[2][0]\n",
    "\n",
    "ax.set_xlabel('True Value')\n",
    "ax.set_ylabel('Predicted Value (Debris)')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_pred_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "ax = ax1[2][1]\n",
    "\n",
    "ax.set_xlabel('True Value')\n",
    "\n",
    "ax.grid(True)\n",
    "\n",
    "ax.scatter(y_test_norm, y_phys_norm, marker='.', color='dodgerblue')\n",
    "\n",
    "ax.plot([0,1], [0,1], color='red')\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7420072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
