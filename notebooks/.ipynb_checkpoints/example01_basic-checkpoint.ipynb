{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "going-typing",
   "metadata": {},
   "source": [
    "# AMLD 2021\n",
    "\n",
    "##### Machine Learning in Science: Encoding physical constraints and good development practices\n",
    "\n",
    "\n",
    "## Example 01 - Basic Reproducability\n",
    "\n",
    "In this notebook, we start by demonstrating some of the more fundamental approaches to reproducability. The models that we will be training are simplified versions of the models used in a real astrophysics problem. Later in the workshop, we will improve these models to obey physical laws, such as the conservation of mass.\n",
    "\n",
    "### Workshop Organizers\n",
    "Dr. Maria Han Veiga (University of Michigan, USA)\n",
    "\n",
    "Dr. Miles Timpe (University of Zurich, Switzerland)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-dialogue",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "strange-penalty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.9 (default, Aug 31 2020, 12:42:55) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# We can define a global seed value to make our lives easier\n",
    "seed = 42\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from sys import version\n",
    "print(f\"Python version: {version}\")\n",
    "\n",
    "# TensorFlow\n",
    "#import tensorflow as tf\n",
    "#tf.random.set_seed(seed) # TensorFlow2\n",
    "#tf.compat.v1.set_random_seed(random_seed)  # TensorFlow1\n",
    "#print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-tamil",
   "metadata": {},
   "source": [
    "### Load training data\n",
    "\n",
    "The datasets for this problem are relatively small by machine learning standards. Therefore, we provide them as CSV files. The train and test datasets together contain data on 14,856 pairwise collisions between planets. To keep things simple, we will only focus on three targets, which are subject to physical conservation laws; the mass of the largest remnant (\"lr_mass\"), the mass of the second largest remnant (\"slr_mass\"), and the mass of the collision debris (\"debris_mass\"). The mass of these three objects should match exactly the total mass that went into the collisions (\"mtotal\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forced-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'lr_mass' #, 'slr_mass', 'debris_mass'\n",
    "\n",
    "features = ['collision_id', 'mtotal', 'gamma', 'b_inf', 'v_inf',\n",
    "            'targ_core_fraction', 'targ_omega', 'targ_theta', 'targ_phi',\n",
    "            'proj_core_fraction', 'proj_omega', 'proj_theta', 'proj_phi',\n",
    "            target]\n",
    "\n",
    "x_train = pd.read_csv('../datasets/train.csv', usecols=features)\n",
    "x_test  = pd.read_csv('../datasets/test.csv', usecols=features)\n",
    "\n",
    "y_train = x_train.pop(target)\n",
    "y_test  = x_test.pop(target)\n",
    "\n",
    "ids_train = list(x_train.pop('collision_id'))\n",
    "ids_test  = list(x_test.pop('collision_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-special",
   "metadata": {},
   "source": [
    "### Scale data and save the scaler\n",
    "\n",
    "While most of the focus in machine learning is on the models, an important component of reproducability are the scaling methods. Here, we are using scikit-learn's standard scaler. Anyone that wants to reproduce our results will need to know exactly how the data was scaled prior to training. Therefore, once we have fit the scaler, we save it so that it can be loaded at a later date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressive-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn's StandardScaler\n",
    "x_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# Fit scaler to training data\n",
    "x_scaler.fit(x_train)\n",
    "\n",
    "# Save scaler\n",
    "dump(x_scaler, f\"x_scaler_{target}.joblib\")\n",
    "\n",
    "# Make sure to apply same scaler to train and test!\n",
    "scaled_x_train = x_scaler.transform(x_train)\n",
    "scaled_x_test  = x_scaler.transform(x_test)\n",
    "\n",
    "scaled_x_train = pd.DataFrame(scaled_x_train, columns=x_train.columns)\n",
    "scaled_x_test  = pd.DataFrame(scaled_x_test, columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "agricultural-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale target\n",
    "y_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "y_scaler.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Save scaler\n",
    "dump(y_scaler, f\"y_scaler_{target}.joblib\")\n",
    "\n",
    "scaled_y_train = y_scaler.transform(y_train.values.reshape(-1, 1))\n",
    "scaled_y_test  = y_scaler.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "scaled_y_train = pd.Series(data=np.squeeze(scaled_y_train), name=target)\n",
    "scaled_y_test  = pd.Series(data=np.squeeze(scaled_y_test), name=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wicked-ocean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mtotal</th>\n",
       "      <th>gamma</th>\n",
       "      <th>b_inf</th>\n",
       "      <th>v_inf</th>\n",
       "      <th>targ_core_fraction</th>\n",
       "      <th>targ_omega</th>\n",
       "      <th>targ_theta</th>\n",
       "      <th>targ_phi</th>\n",
       "      <th>proj_core_fraction</th>\n",
       "      <th>proj_omega</th>\n",
       "      <th>proj_theta</th>\n",
       "      <th>proj_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.129663</td>\n",
       "      <td>-0.412157</td>\n",
       "      <td>1.688591</td>\n",
       "      <td>1.463011</td>\n",
       "      <td>-1.200600</td>\n",
       "      <td>-0.991256</td>\n",
       "      <td>-0.794165</td>\n",
       "      <td>0.527538</td>\n",
       "      <td>0.538834</td>\n",
       "      <td>-0.272755</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>-1.378417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.580563</td>\n",
       "      <td>0.083088</td>\n",
       "      <td>0.381770</td>\n",
       "      <td>0.688370</td>\n",
       "      <td>0.897798</td>\n",
       "      <td>1.266838</td>\n",
       "      <td>-0.118932</td>\n",
       "      <td>-1.099525</td>\n",
       "      <td>-0.402843</td>\n",
       "      <td>-0.698354</td>\n",
       "      <td>-0.130287</td>\n",
       "      <td>1.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.316276</td>\n",
       "      <td>-1.277910</td>\n",
       "      <td>-1.530752</td>\n",
       "      <td>-0.858887</td>\n",
       "      <td>0.934271</td>\n",
       "      <td>0.461699</td>\n",
       "      <td>-0.034064</td>\n",
       "      <td>-1.273318</td>\n",
       "      <td>-1.402607</td>\n",
       "      <td>-1.381865</td>\n",
       "      <td>0.666310</td>\n",
       "      <td>-1.046404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601613</td>\n",
       "      <td>1.157604</td>\n",
       "      <td>-1.169237</td>\n",
       "      <td>-0.885574</td>\n",
       "      <td>-1.610655</td>\n",
       "      <td>-0.716263</td>\n",
       "      <td>-0.507535</td>\n",
       "      <td>0.026861</td>\n",
       "      <td>-0.684194</td>\n",
       "      <td>0.803207</td>\n",
       "      <td>-0.442403</td>\n",
       "      <td>1.438486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.465914</td>\n",
       "      <td>-0.609071</td>\n",
       "      <td>1.095204</td>\n",
       "      <td>-0.985363</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.875065</td>\n",
       "      <td>1.173906</td>\n",
       "      <td>-1.062015</td>\n",
       "      <td>-0.023888</td>\n",
       "      <td>-0.907480</td>\n",
       "      <td>-1.600869</td>\n",
       "      <td>-0.055434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mtotal     gamma     b_inf     v_inf  targ_core_fraction  targ_omega  \\\n",
       "0 -0.129663 -0.412157  1.688591  1.463011           -1.200600   -0.991256   \n",
       "1 -0.580563  0.083088  0.381770  0.688370            0.897798    1.266838   \n",
       "2 -0.316276 -1.277910 -1.530752 -0.858887            0.934271    0.461699   \n",
       "3 -0.601613  1.157604 -1.169237 -0.885574           -1.610655   -0.716263   \n",
       "4  1.465914 -0.609071  1.095204 -0.985363            0.093500    0.875065   \n",
       "\n",
       "   targ_theta  targ_phi  proj_core_fraction  proj_omega  proj_theta  proj_phi  \n",
       "0   -0.794165  0.527538            0.538834   -0.272755    0.986286 -1.378417  \n",
       "1   -0.118932 -1.099525           -0.402843   -0.698354   -0.130287  1.040935  \n",
       "2   -0.034064 -1.273318           -1.402607   -1.381865    0.666310 -1.046404  \n",
       "3   -0.507535  0.026861           -0.684194    0.803207   -0.442403  1.438486  \n",
       "4    1.173906 -1.062015           -0.023888   -0.907480   -1.600869 -0.055434  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-slave",
   "metadata": {},
   "source": [
    "### k-fold cross-validation \n",
    "\n",
    "We can specify the random state when shuffling and splitting the data for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loving-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold of training data\n",
    "#skf = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "\n",
    "#skf.get_n_splits(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "varied-funds",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction r2_score: 0.9881\n"
     ]
    }
   ],
   "source": [
    "# Define model (MLP)\n",
    "model = MLPRegressor(hidden_layer_sizes=[24,24,24],\n",
    "                     max_iter=1000, early_stopping=True,\n",
    "                     random_state=seed)\n",
    "\n",
    "\n",
    "# Fit model\n",
    "model.fit(scaled_x_train, scaled_y_train)\n",
    "\n",
    "# Make predictions\n",
    "scaled_y_pred = model.predict(scaled_x_test)\n",
    "\n",
    "# Apply inverse scaling to the model predictions\n",
    "y_pred = pd.Series(y_scaler.inverse_transform(scaled_y_pred), name='y_pred').values\n",
    "\n",
    "# Calculate the quality of the predictions with the r2 score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Save the model with joblib\n",
    "dump(model, f\"regressor_mlp_{target}.joblib\") \n",
    "\n",
    "\n",
    "print(f\"Prediction r2_score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-heaven",
   "metadata": {},
   "source": [
    "### Does the vanilla model obey physics?\n",
    "\n",
    "While the data is physically consistent, the model has no knowledge of physical laws. We will discuss solutions to this later in the workshop, but right now let's quickly check how bad the physics violations are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demographic-writer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Violations: 468\n",
      "Physics-aware r2 score: 0.9886\n"
     ]
    }
   ],
   "source": [
    "# Counter for violations\n",
    "i = 0\n",
    "\n",
    "y_pred_constrained = []\n",
    "\n",
    "for mtot, y in zip(x_test.mtotal, y_pred):\n",
    "    \n",
    "    # If mass is greater than the initial total mass\n",
    "    if y > mtot:\n",
    "        i += 1\n",
    "    # If mass is negative\n",
    "    elif y < 0:\n",
    "        i += 1\n",
    "        \n",
    "    y_pred_constrained.append(np.max([0.0, np.min([y, mtot])]))\n",
    "        \n",
    "print(f\"Violations: {i}\")\n",
    "\n",
    "r2_constrained = r2_score(y_test, y_pred_constrained)\n",
    "\n",
    "print(f\"Physics-aware r2 score: {r2_constrained:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-producer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
